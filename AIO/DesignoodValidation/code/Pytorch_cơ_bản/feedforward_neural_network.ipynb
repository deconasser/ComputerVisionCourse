{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "feedforward_neural_network.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ7dwEeDlLEa"
      },
      "source": [
        "import torch \n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKUMZHWZliLq"
      },
      "source": [
        "# Devide configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9HvCz0elhxb"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkqKZve8lzHA"
      },
      "source": [
        "# Hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWtljeqIl368"
      },
      "source": [
        "input_size = 28*28\n",
        "hidden_size = 500\n",
        "num_classes = 10\n",
        "num_epochs = 10 \n",
        "batch_size = 100\n",
        "learning_rate = 0.001"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpoR8btTmCP-"
      },
      "source": [
        "# MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35xHKxvsmGfd",
        "outputId": "6b8d839b-d580-449b-8e89-bec5d420d940"
      },
      "source": [
        "!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
        "!tar -zxvf MNIST.tar.gz"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-25 06:07:08--  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Resolving www.di.ens.fr (www.di.ens.fr)... 129.199.99.14\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.di.ens.fr/~lelarge/MNIST.tar.gz [following]\n",
            "--2021-03-25 06:07:09--  https://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-gzip]\n",
            "Saving to: ‘MNIST.tar.gz.1’\n",
            "\n",
            "MNIST.tar.gz.1          [      <=>           ]  33.20M  5.01MB/s    in 18s     \n",
            "\n",
            "2021-03-25 06:07:28 (1.80 MB/s) - ‘MNIST.tar.gz.1’ saved [34813078]\n",
            "\n",
            "MNIST/\n",
            "MNIST/raw/\n",
            "MNIST/raw/train-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "MNIST/raw/train-images-idx3-ubyte\n",
            "MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-images-idx3-ubyte\n",
            "MNIST/raw/train-images-idx3-ubyte.gz\n",
            "MNIST/processed/\n",
            "MNIST/processed/training.pt\n",
            "MNIST/processed/test.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2I-GSMgmLQL"
      },
      "source": [
        "train_dataset = torchvision.datasets.MNIST(root='./', \n",
        "                                           train=True, \n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./', \n",
        "                                          train=False, \n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader (input pipeline)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzLdOMQImRyn"
      },
      "source": [
        "# Fully connected neural network with one hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaPk7kLEmZih"
      },
      "source": [
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super(NeuralNet, self).__init__()\n",
        "    self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    out = self.fc1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.fc2(out)\n",
        "\n",
        "    return out"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHZrQPO_3zG7"
      },
      "source": [
        "# Create model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4gUeMhb4Ixg"
      },
      "source": [
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVeAVB--4W9g"
      },
      "source": [
        "# Loss and optimizer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8kv2Ooq4Ypu"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHIgCUqxAJeu"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sipdAmisALa0",
        "outputId": "81d6d6ff-1cb5-4af4-e45a-025133ebe6cf"
      },
      "source": [
        "total_step = len(train_loader)  \n",
        "for epoch in range(num_epochs):\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    # Move tensor to the configured device \n",
        "    images = images.reshape(-1, input_size).to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # forward pass\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # backward and optimizer \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1) % 100 == 0:\n",
        "          print ('Epoch [{}/{}], Step [{}/{}], Loss: {}' \n",
        "                  .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [100/600], Loss: 2.283475875854492\n",
            "Epoch [1/10], Step [200/600], Loss: 2.2633490562438965\n",
            "Epoch [1/10], Step [300/600], Loss: 2.2417337894439697\n",
            "Epoch [1/10], Step [400/600], Loss: 2.208282232284546\n",
            "Epoch [1/10], Step [500/600], Loss: 2.18100643157959\n",
            "Epoch [1/10], Step [600/600], Loss: 2.1789002418518066\n",
            "Epoch [2/10], Step [100/600], Loss: 2.14066743850708\n",
            "Epoch [2/10], Step [200/600], Loss: 2.102980136871338\n",
            "Epoch [2/10], Step [300/600], Loss: 2.087911367416382\n",
            "Epoch [2/10], Step [400/600], Loss: 2.0868430137634277\n",
            "Epoch [2/10], Step [500/600], Loss: 2.0339438915252686\n",
            "Epoch [2/10], Step [600/600], Loss: 1.9785929918289185\n",
            "Epoch [3/10], Step [100/600], Loss: 1.9783756732940674\n",
            "Epoch [3/10], Step [200/600], Loss: 1.9386478662490845\n",
            "Epoch [3/10], Step [300/600], Loss: 1.8822011947631836\n",
            "Epoch [3/10], Step [400/600], Loss: 1.8424525260925293\n",
            "Epoch [3/10], Step [500/600], Loss: 1.8966349363327026\n",
            "Epoch [3/10], Step [600/600], Loss: 1.825413703918457\n",
            "Epoch [4/10], Step [100/600], Loss: 1.7656599283218384\n",
            "Epoch [4/10], Step [200/600], Loss: 1.7784274816513062\n",
            "Epoch [4/10], Step [300/600], Loss: 1.6237740516662598\n",
            "Epoch [4/10], Step [400/600], Loss: 1.7233467102050781\n",
            "Epoch [4/10], Step [500/600], Loss: 1.6042791604995728\n",
            "Epoch [4/10], Step [600/600], Loss: 1.6576247215270996\n",
            "Epoch [5/10], Step [100/600], Loss: 1.5544030666351318\n",
            "Epoch [5/10], Step [200/600], Loss: 1.5401396751403809\n",
            "Epoch [5/10], Step [300/600], Loss: 1.5084283351898193\n",
            "Epoch [5/10], Step [400/600], Loss: 1.4460461139678955\n",
            "Epoch [5/10], Step [500/600], Loss: 1.400965690612793\n",
            "Epoch [5/10], Step [600/600], Loss: 1.4439767599105835\n",
            "Epoch [6/10], Step [100/600], Loss: 1.2743232250213623\n",
            "Epoch [6/10], Step [200/600], Loss: 1.3297244310379028\n",
            "Epoch [6/10], Step [300/600], Loss: 1.3058665990829468\n",
            "Epoch [6/10], Step [400/600], Loss: 1.1812033653259277\n",
            "Epoch [6/10], Step [500/600], Loss: 1.25236177444458\n",
            "Epoch [6/10], Step [600/600], Loss: 1.1599111557006836\n",
            "Epoch [7/10], Step [100/600], Loss: 1.1608351469039917\n",
            "Epoch [7/10], Step [200/600], Loss: 1.1050348281860352\n",
            "Epoch [7/10], Step [300/600], Loss: 1.15165376663208\n",
            "Epoch [7/10], Step [400/600], Loss: 1.1093002557754517\n",
            "Epoch [7/10], Step [500/600], Loss: 1.1006157398223877\n",
            "Epoch [7/10], Step [600/600], Loss: 1.1341780424118042\n",
            "Epoch [8/10], Step [100/600], Loss: 1.081963300704956\n",
            "Epoch [8/10], Step [200/600], Loss: 1.0473867654800415\n",
            "Epoch [8/10], Step [300/600], Loss: 1.0522263050079346\n",
            "Epoch [8/10], Step [400/600], Loss: 1.1102885007858276\n",
            "Epoch [8/10], Step [500/600], Loss: 1.0321906805038452\n",
            "Epoch [8/10], Step [600/600], Loss: 0.889016330242157\n",
            "Epoch [9/10], Step [100/600], Loss: 0.9260755181312561\n",
            "Epoch [9/10], Step [200/600], Loss: 0.8865748643875122\n",
            "Epoch [9/10], Step [300/600], Loss: 0.9503741264343262\n",
            "Epoch [9/10], Step [400/600], Loss: 0.956565260887146\n",
            "Epoch [9/10], Step [500/600], Loss: 0.8064313530921936\n",
            "Epoch [9/10], Step [600/600], Loss: 0.9889825582504272\n",
            "Epoch [10/10], Step [100/600], Loss: 0.8861051797866821\n",
            "Epoch [10/10], Step [200/600], Loss: 0.8207511305809021\n",
            "Epoch [10/10], Step [300/600], Loss: 0.9144678711891174\n",
            "Epoch [10/10], Step [400/600], Loss: 0.7767316699028015\n",
            "Epoch [10/10], Step [500/600], Loss: 0.8441546559333801\n",
            "Epoch [10/10], Step [600/600], Loss: 0.7477918267250061\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLCQUDWyBb9t"
      },
      "source": [
        "# Test model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WglUc25OBbC6",
        "outputId": "86ce5457-9ed4-439e-85dd-c40f45eb4a72"
      },
      "source": [
        "with torch.no_grad():\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for images, labels in test_loader:\n",
        "    images = images.reshape(-1, input_size).to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "  \n",
        "  print('Accuracy: {}'.format(100 * correct / total))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 84.01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DETx5Y9aCWb5"
      },
      "source": [
        "# Save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-kgIthZCXP_"
      },
      "source": [
        "torch.save(model.state_dict(), 'NN_model.ckpt')"
      ],
      "execution_count": 16,
      "outputs": []
    }
  ]
}