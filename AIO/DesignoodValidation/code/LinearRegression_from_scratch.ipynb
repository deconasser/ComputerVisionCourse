{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LinearRegression.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbPpZlTx0-nE"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omj4rFGO2HYQ"
      },
      "source": [
        "class LinearRegression:\n",
        "  def __init__(self, lr=0.001, iterations=1000):\n",
        "    self.lr = lr \n",
        "    self.iterations = iterations\n",
        "\n",
        "  def y_pred(self, X, w):\n",
        "    \"\"\"\n",
        "      w: weight tensor\n",
        "      X: input tensor\n",
        "    \"\"\"\n",
        "    return torch.mm(torch.transpose(w, 0, 1), X) \n",
        "  \n",
        "  def loss(self, ypred, y):\n",
        "    \"\"\"\n",
        "      loss function - to measure the loss between estimated vs ground truth\n",
        "    \"\"\"\n",
        "    l = 1 / self.m * torch.sum(torch.pow(y-ypred, 2))\n",
        "\n",
        "  def gradient_descent(self, w, X, y, ypred):\n",
        "    \"\"\"\n",
        "      dCdW: derivative of cost function\n",
        "      w_update: change in weight tensor after each iteration\n",
        "    \"\"\"\n",
        "    dCdW = 2*self.m * torch.mm(X, torch.transpose(ypred-y, 0, 1))\n",
        "    w_update = w - self.lr * dCdW \n",
        "    \n",
        "    return w_update\n",
        "  \n",
        "  def run(self, X, y):\n",
        "    \"\"\"\n",
        "      type y: tensor object\n",
        "      type X: tensor object\n",
        "    \"\"\"\n",
        "    bias = torch.ones((1, X.shape[1]))\n",
        "    X = torch.cat((bias, X), dim=0)\n",
        "\n",
        "    self.m = X.shape[1]\n",
        "    self.n = X.shape[0]\n",
        "\n",
        "    w = torch.zeros((self.n, 1))\n",
        "\n",
        "    for iteration in range(1, self.iterations+1):\n",
        "      ypred = self.y_pred(X, w)\n",
        "      cost = self.loss(ypred, y)\n",
        "\n",
        "      if iteration % 100 == 0:\n",
        "        print(f'Loss at iteration {iteration} is {cost}')\n",
        "      \n",
        "      w = self.gradient_descent(w, X, y, ypred)\n",
        "    \n",
        "    return w "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RV9sF65_8Y69"
      },
      "source": [
        "\"\"\"\n",
        "  X: random initialization of input tensor\n",
        "  y: random initialization of input tensor\n",
        "\"\"\"\n",
        "X = torch.rand(1, 500)\n",
        "y = 2*X + 3 + torch.randn(1, 500) * 0.01\n",
        "\n",
        "model = LinearRegression(0.001, 1000)\n",
        "w = model.run(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}