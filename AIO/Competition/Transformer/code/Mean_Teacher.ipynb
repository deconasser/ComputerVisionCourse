{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"vKueZZ6y68Ln"},"outputs":[],"source":["!git clone https://github.com/anminhhung/small_dog_cat_dataset"]},{"cell_type":"code","source":["!pip install timm"],"metadata":{"id":"qX5JDLDXLJ1m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","from torch.utils.data import DataLoader, Dataset, ConcatDataset, SubsetRandomSampler\n","from torchvision.datasets import MNIST\n","from torch.nn import functional as F\n","from torchvision import datasets, transforms\n","from torchvision.models import resnet18\n","import torchvision\n","import torch.nn as nn\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import KFold\n","import cv2\n","import os\n","\n","import albumentations"],"metadata":{"id":"XImKx6lt7IB9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","    Function for computing the accuracy of the predictions over the entire data_loader\n","'''\n","def get_accuracy(model, data_loader, device):\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        model.eval()\n","        for images, labels in data_loader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    return 100*(correct/total)\n","\n","'''\n","    Function for plotting training and validation losses\n","'''\n","def plot_losses(train_acc, valid_acc, train_loss, valid_loss):\n","    # change the style of the plots to seaborn\n","    plt.style.use('seaborn')\n","\n","    train_acc = np.array(train_acc)\n","    valid_acc = np.array(valid_acc)\n","\n","    fig, (ax1, ax2) = plt.subplots(1, 2)\n","\n","    ax1.plot(train_acc, color=\"blue\", label=\"Train_acc\")\n","    ax1.plot(valid_acc, color=\"red\", label=\"Validation_acc\")\n","    ax1.set(title=\"Acc over epochs\",\n","            xlabel=\"Epoch\",\n","            ylabel=\"Acc\")\n","    ax1.legend()\n","\n","    ax2.plot(train_loss, color=\"blue\", label=\"Train_loss\")\n","    ax2.plot(valid_loss, color=\"red\", label=\"Validation_loss\")\n","    ax2.set(title=\"loss over epochs\",\n","            xlabel=\"Epoch\",\n","            ylabel=\"Loss\")\n","    ax2.legend()\n","\n","    fig.show()\n","\n","    # change the plot style to default\n","    plt.style.use('default')\n","\n","'''\n","    function for the validation step of the training loop\n","'''\n","def validate(valid_loader, model, criterion, device):\n","    model.eval()\n","    running_loss = 0\n","\n","    for images, labels in valid_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        # forward pass and record loss\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        running_loss += loss.item()\n","\n","    epoch_loss = running_loss / len(valid_loader)\n","\n","    return model, epoch_loss\n","\n","\n","def update_teacher_params(student, teacher, alpha, global_step):\n","    # Use the true average until the exponential average is more correct\n","    alpha = min(1 - 1 / (global_step + 1), alpha)\n","    for ema_param, param in zip(teacher.parameters(), student.parameters()):\n","        ema_param.data.mul_(alpha).add_(1 - alpha, param.data)\n","\n","'''\n","    function for the training step of the training loop\n","'''\n","def train(train_loader, teacher, student, class_criterion, consistency_criterion, optimizer, devicdevic, epoch):\n","    teacher.train()\n","    student.train()\n","\n","    running_loss = 0\n","    global_step = 0\n","    for images, labels in train_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        # forward pass\n","        student_pred = student(images)\n","        teacher_pred= teacher(images)\n","\n","        student_class, student_consistency = student_pred, student_pred\n","\n","        student_class_loss = class_criterion(student_class, labels) # CrossEntropy\n","        consistency_loss = consistency_criterion(student_consistency, teacher_pred) # MSE\n","\n","        loss = student_class_loss + consistency_loss\n","\n","        running_loss += loss.item()\n","\n","        # backward\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        global_step += 1\n","        update_teacher_params(student, teacher, 0.995, global_step)\n","\n","    epoch_loss = running_loss / len(train_loader)\n","\n","    return student, optimizer, epoch_loss\n","\n","'''\n","    function defining the entire training loop\n","'''\n","def training_loop(teacher, student, class_criterion, consistency_criterion, optimizer, train_loader, valid_loader, epochs, device, print_every=1):\n","    if not os.path.exists(\"save_model\"):\n","      os.mkdir(\"save_model\")\n","    # set object for storing metrics\n","    best_loss = 1e10\n","    train_losses = []\n","    valid_losses = []\n","    list_train_acc = []\n","    list_val_acc = []\n","\n","    # train model\n","    for epoch in range(0, epochs):\n","        # training\n","        student, optimizer, train_loss = train(train_loader, teacher, student, class_criterion, consistency_criterion, optimizer, device, epoch)\n","\n","        # validation\n","        with torch.no_grad():\n","            student, valid_loss = validate(valid_loader, student, class_criterion, device)\n","\n","        if epoch % print_every == print_every - 1:\n","            train_acc = get_accuracy(student, train_loader, device=device)\n","            valid_acc = get_accuracy(student, valid_loader, device=device)\n","\n","\n","            print('Epochs: {}, Train_loss: {}, Valid_loss: {}, Train_accuracy: {}, Valid_accuracy: {}'.format(\n","                    epoch, train_loss, valid_loss, train_acc, valid_acc\n","                    ))\n","\n","            list_train_acc.append(train_acc)\n","            list_val_acc.append(valid_acc)\n","            train_losses.append(train_loss)\n","            valid_losses.append(valid_loss)\n","\n","    plot_losses(list_train_acc, list_val_acc, train_losses, valid_losses)\n","\n","    return student"],"metadata":{"id":"ANb0eLLv7L4y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DogCatDataset(Dataset):\n","  def __init__(self, root_dir, transform=None):\n","    self.list_images_path = []\n","    self.list_labels = []\n","    self.one_hot_label = {\"dogs\": 0, \"cats\": 1}\n","    for sub_dir in os.listdir(root_dir):\n","      path_sub_dir = os.path.join(root_dir, sub_dir)\n","      for image_name in os.listdir(path_sub_dir):\n","        image_path = os.path.join(path_sub_dir, image_name)\n","        label = sub_dir\n","        self.list_images_path.append(image_path)\n","        self.list_labels.append(label)\n","\n","    self.transform = transform\n","\n","  def __len__(self):\n","    return len(self.list_images_path)\n","\n","  def __getitem__(self, idx):\n","    image = cv2.imread(self.list_images_path[idx])\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    image = cv2.resize(image, (224, 224))\n","    label = np.array(self.one_hot_label[self.list_labels[idx]]) # .astype('float')\n","\n","    if self.transform:\n","      res = self.transform(image=image)\n","      image = res['image'].astype(np.float32)\n","    else:\n","      image = image.astype(np.float32)\n","\n","    image = image.transpose(2, 0, 1)\n","    sample = (image, label)\n","\n","    return sample # image, label"],"metadata":{"id":"JhkEbRBh7cHY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_transforms(image_size=(224, 224)):\n","\n","    transforms_train = albumentations.Compose([\n","        albumentations.HorizontalFlip(p=0.5),\n","        albumentations.ImageCompression(quality_lower=99, quality_upper=100),\n","        albumentations.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=10, border_mode=0, p=0.7),\n","        # albumentations.Resize(image_size, image_size),\n","        # albumentations.Cutout(max_h_size=int(image_size * 0.4), max_w_size=int(image_size * 0.4), num_holes=1, p=0.5),\n","        albumentations.Normalize(),\n","        albumentations.RandomBrightnessContrast(p=0.2),\n","    ])\n","\n","    transforms_val = albumentations.Compose([\n","        # albumentations.Resize(image_size, image_size),\n","        albumentations.Normalize()\n","    ])\n","\n","    return transforms_train, transforms_val"],"metadata":{"id":"bQ1hY2og7fSo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transforms_train, transforms_val = get_transforms(image_size=(224, 224))"],"metadata":{"id":"TujPWRFG9Z8P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transformed_train_data = DogCatDataset('small_dog_cat_dataset/train', transform=transforms_train)\n","transformed_test_data = DogCatDataset('small_dog_cat_dataset/test', transform=transforms_val)"],"metadata":{"id":"JfnsHyDr8cTq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data_loader = DataLoader(transformed_train_data, batch_size=32, shuffle=True)\n","test_data_loader = DataLoader(transformed_test_data, batch_size=32, shuffle=True)\n"],"metadata":{"id":"Rjuskqzj3kd2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import timm\n","\n","class my_Net(nn.Module):\n","  def __init__(self, num_class=2, model_name = \"vit_base_patch16_224\", pretrained = True):\n","    super().__init__()\n","\n","    self.model_name = model_name\n","    self.model = timm.create_model(self.model_name, pretrained=pretrained, num_classes=num_class)\n","\n","  def forward(self, x):\n","    x = self.model(x)\n","    return x\n"],"metadata":{"id":"_5USxw5g9lTu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"],"metadata":{"id":"sYS1owcQ9r20"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def softmax_mse_loss(input_logits, target_logits):\n","\n","    assert input_logits.size() == target_logits.size()\n","    input_softmax = F.softmax(input_logits, dim=1)\n","    target_softmax = F.softmax(target_logits, dim=1)\n","    num_classes = input_logits.size()[1]\n","    return F.mse_loss(input_softmax, target_softmax, size_average=False) # / num_classes\n","\n","def sigmoid_rampup(current, rampup_length):\n","    if rampup_length == 0:\n","        return 1.0\n","    else:\n","        current = np.clip(current, 0.0, rampup_length)\n","        phase = 1.0 - current / rampup_length\n","        return float(np.exp(-5.0 * phase * phase))\n","\n","def get_current_consistency_weight(epoch):\n","    return 100.0 * sigmoid_rampup(epoch, 5)\n","\n"],"metadata":{"id":"XroMOInXlZTu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["student = my_Net(num_class=2, model_name = \"vit_base_patch16_224\", pretrained = True).to(device)\n","teacher = my_Net(num_class=2, model_name = \"vit_base_patch16_224\", pretrained = True).to(device)\n","\"\"\"\n","Detach params for Exponential Moving Average Model.\n","Cập nhật các thông số này theo công thức EMA thay vì sử dụng backprop.\n","\"\"\"\n","for param in teacher.parameters():\n","    param.detach_()\n","\n","optimizer = torch.optim.Adam(student.parameters(), lr=0.001)\n","class_criterion = nn.CrossEntropyLoss()"],"metadata":{"id":"aekY8Tn31xvZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["student_model = training_loop(teacher, student, class_criterion, softmax_mse_loss, optimizer, train_data_loader, test_data_loader, 3, device)"],"metadata":{"id":"9C8Jfh929tQi"},"execution_count":null,"outputs":[]}]}