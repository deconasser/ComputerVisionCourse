{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyOKJwmQubJgqfTVz9SfoJ1r"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"liRhCZw3QQDO","executionInfo":{"status":"ok","timestamp":1686724912047,"user_tz":-420,"elapsed":5879,"user":{"displayName":"Minh Hùng An","userId":"12219570561405750876"}},"outputId":"372d939c-8d34-442d-8aef-994d15b34482"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'small_dog_cat_dataset'...\n","remote: Enumerating objects: 2608, done.\u001b[K\n","remote: Total 2608 (delta 0), reused 0 (delta 0), pack-reused 2608\u001b[K\n","Receiving objects: 100% (2608/2608), 55.84 MiB | 13.61 MiB/s, done.\n","Resolving deltas: 100% (1/1), done.\n"]}],"source":["!git clone https://github.com/anminhhung/small_dog_cat_dataset"]},{"cell_type":"code","source":["import torchvision.transforms as transforms\n","import torchvision.models as models\n","import torchvision.transforms.functional as TF\n","import torch.nn as nn\n","import os\n","from PIL import Image\n","import numpy as np\n","\n","from google.colab.patches import cv2_imshow"],"metadata":{"id":"lEoCQXoIQdxF","executionInfo":{"status":"ok","timestamp":1686725247485,"user_tz":-420,"elapsed":711,"user":{"displayName":"Minh Hùng An","userId":"12219570561405750876"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def top_k(a):\n","    k = 6\n","    idx = np.argpartition(a.ravel(),a.size-k)[-k:]\n","    return np.column_stack(np.unravel_index(idx, a.shape))\n","\n","def get_attentive_regions(image):\n","    \"\"\"\n","    CIFAR return top k from 8x8\n","    ImageNet return top k from 7x7\n","    \"\"\"\n","    x = TF.to_tensor(image).unsqueeze_(0).cuda()\n","    output = model(x)\n","    last_feature_map = output[0][-1].detach().cpu().numpy()\n","    return top_k(last_feature_map)\n","\n","def replace_attentive_regions(rand_img, image, attentive_regions):\n","    \"\"\"\n","    rand_img: the img to be replaced\n","    image: where the 'patches' come from\n","    attentive_regions: an array contains the coordinates of attentive regions\n","    \"\"\"\n","    np_rand_img, np_img = np.array(rand_img), np.array(image)\n","    for attentive_region in attentive_regions:\n","        replace_attentive_region(np_rand_img, np_img, attentive_region)\n","    return Image.fromarray(np_rand_img)\n","\n","def replace_attentive_region(np_rand_img, np_img, attentive_region):\n","    x, y = attentive_region\n","    x1, x2, y1, y2 = grid_size * x, grid_size * (x+1), grid_size * y, grid_size * (y+1)\n","    region = np_img[x1:x2, y1: y2]\n","    np_rand_img[x1:x2, y1:y2] = region\n","\n","def select_random_image(i):\n","    rand_index = np.random.randint(0, len(img_paths))\n","    while rand_index == i:\n","        rand_index = np.random.randint(0, len(img_paths))\n","    rand_img = Image.open(root+img_paths[rand_index])\n","    return rand_img\n","\n","model = models.resnet50(pretrained=True)\n","temp_model = nn.Sequential(*list(model.children())[:-2])\n","model = temp_model.cuda()\n","grid_size = 32\n","\n","root = 'small_dog_cat_dataset/test/cats/'\n","img_paths = os.listdir(root)\n","if not os.path.exists('mixed_images'):\n","  os.mkdir('mixed_images')\n","\n","for i, rel_path in enumerate(img_paths):\n","  try:\n","    img_path = root + rel_path\n","    img = Image.open(img_path).resize((224, 224))\n","    rand_img = select_random_image(i)\n","    ori_size = rand_img.size\n","    rand_img.resize((224, 224))\n","    attentive_regions = get_attentive_regions(img)\n","    rand_img = replace_attentive_regions(rand_img, img, attentive_regions)\n","    rand_img.resize(ori_size)\n","    rand_img.save('./mixed_images/{}'.format(rel_path))\n","  except:\n","    pass"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XnZP-vRQQVUU","executionInfo":{"status":"ok","timestamp":1686725334090,"user_tz":-420,"elapsed":8306,"user":{"displayName":"Minh Hùng An","userId":"12219570561405750876"}},"outputId":"15460127-d8b6-458a-a63f-45303001fdbd"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]}]}]}